{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9158444",
   "metadata": {},
   "source": [
    "# **Training RL policies**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b01847",
   "metadata": {},
   "source": [
    "This notebook is used for training RL_policies. At the moment this is still exploratory, but later this should change. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be0ce0f",
   "metadata": {},
   "source": [
    "For training the RL policies we use sb3, as minigrid recommends. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d930d8",
   "metadata": {},
   "source": [
    "### **Register  and loading an env**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d08e29b",
   "metadata": {},
   "source": [
    "First we need to register an env  to gymnasium (once). Note that here we use already the ProbalisticEnvWrapper class that we made. For more info about how we load the envs see /envs/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5604bea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gym] Registered environment: CrossingEnv-v0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noah/Noah_tmp/thesis/Minigrid2Storm/.venv/lib/python3.12/site-packages/gymnasium/envs/registration.py:636: UserWarning: \u001b[33mWARN: Overriding environment CrossingEnv-v0 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CrossingEnv-v0'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from envs.registry import register_env\n",
    "\n",
    "env_name = \"CrossingEnv\"\n",
    "register_env(f\"./envs/configs/goal_state/{env_name}.yaml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd562b5",
   "metadata": {},
   "source": [
    "Once we have it registered, we need to load it from gymnasium again. Additionally, the observatsion returned by the step type is a dictionary. However, we use the PPO algorithm and it does expect a different format from the observation. We use the ImgObsWrapper, which lets the obs to be only an image, such that it can be porcessed by an CNN. \n",
    "\n",
    "Additionally we use a ReseedWrapper in order to ensure that we have the same seed after reset is called. We need this as if we want to use the DeltaShield during training, we will need to build a storm model before hand. For that we need to ensure that the environment we build the model for is the same as for during training. Hence, the same seed all the time.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "051a9253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from minigrid.wrappers import ImgObsWrapper, ReseedWrapper\n",
    "\n",
    "env = gym.make(f\"{env_name}-v0\")\n",
    "env = ImgObsWrapper(env)\n",
    "env = ReseedWrapper(env, seeds=[42])  # Use a single fixed seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce26ed8",
   "metadata": {},
   "source": [
    "### **Set up a shield**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac86c0c8",
   "metadata": {},
   "source": [
    "If we want to use a shield during training, it needs to be passed as an attribute to the ProbabilisticEnvWrapper. As we applied an ImgObsWrapper to the env, we need to use unwrapped for access to the ProbabilisticEnvWrapper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade200dc",
   "metadata": {},
   "source": [
    "Below we will use a DeltaShield as example which we can then use during training. We won't go into detail on how the delta shield works, but the shield will basically see the lava states as safety-critical and hence, block actions that are likely to end up in a lava cell. \n",
    "\n",
    "For the DeltaShield, one needs to have a model defined first, for which we can use the convert_to_probabilistic_storm(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6013c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN  (IterativeMinMaxLinearEquationSolver.cpp:191): Expected VI operator to be initialized for scheduler extraction. Initializing now, but this is inefficient.\n",
      "WARN  (IterativeMinMaxLinearEquationSolver.cpp:191): Expected VI operator to be initialized for scheduler extraction. Initializing now, but this is inefficient.\n"
     ]
    }
   ],
   "source": [
    "from shield import DeltaShield\n",
    "\n",
    "env.reset()\n",
    "model, _ = env.unwrapped.convert_to_probabilistic_storm()\n",
    "shield = DeltaShield(model, \"Pmin=? [F \\\"lava\\\"]\", delta=0.5)\n",
    "\n",
    "env.unwrapped.set_shield(shield)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958338bc",
   "metadata": {},
   "source": [
    "We can add a logger that will log the activities of the shield for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13a43cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RootLogger root (DEBUG)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup logging for shielding\n",
    "from logging_config import setup_logging\n",
    "import logging\n",
    "\n",
    "setup_logging(log_level=logging.INFO, console_level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac78c74",
   "metadata": {},
   "source": [
    "### **Train the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecccd12",
   "metadata": {},
   "source": [
    "Although the observations of minigrid are now images, the CNN archtiecture of SB3 does not driectly support the Minigrid space. Hence we define our own feature Extractor. For ore info, check out the minigrid documentation: \n",
    "[minigrid training documentation](https://minigrid.farama.org/content/training/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fac08f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "\n",
    "class MinigridFeaturesExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.Space, features_dim: int = 512, normalized_image: bool = False) -> None:\n",
    "        super().__init__(observation_space, features_dim)\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 16, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, (2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        # Compute shape by doing one forward pass\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(torch.as_tensor(observation_space.sample()[None]).float()).shape[1]\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(self.cnn(observations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7558939",
   "metadata": {},
   "source": [
    "As said before, we use the PPO algorithm for training the policy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c870d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "tensorboard is not installed, you can use `pip install tensorboard` to do so",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mstable_baselines3\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcommon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m configure\n\u001b[32m     13\u001b[39m log_dir = \u001b[33m\"\u001b[39m\u001b[33m./logs/ppo_minigrid/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m PPO_logger = \u001b[43mconfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstdout\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtensorboard\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m model = PPO(\u001b[33m\"\u001b[39m\u001b[33mCnnPolicy\u001b[39m\u001b[33m\"\u001b[39m, env, policy_kwargs=policy_kwargs, verbose=\u001b[32m1\u001b[39m, tensorboard_log=\u001b[33m\"\u001b[39m\u001b[33mlogs/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m model.set_logger(PPO_logger)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Noah_tmp/thesis/Minigrid2Storm/.venv/lib/python3.12/site-packages/stable_baselines3/common/logger.py:661\u001b[39m, in \u001b[36mconfigure\u001b[39m\u001b[34m(folder, format_strings)\u001b[39m\n\u001b[32m    658\u001b[39m     format_strings = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mSB3_LOG_FORMAT\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstdout,log,csv\u001b[39m\u001b[33m\"\u001b[39m).split(\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    660\u001b[39m format_strings = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, format_strings))\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m output_formats = [\u001b[43mmake_output_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_suffix\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m format_strings]\n\u001b[32m    663\u001b[39m logger = Logger(folder=folder, output_formats=output_formats)\n\u001b[32m    664\u001b[39m \u001b[38;5;66;03m# Only print when some files will be saved\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Noah_tmp/thesis/Minigrid2Storm/.venv/lib/python3.12/site-packages/stable_baselines3/common/logger.py:467\u001b[39m, in \u001b[36mmake_output_format\u001b[39m\u001b[34m(_format, log_dir, log_suffix)\u001b[39m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m CSVOutputFormat(os.path.join(log_dir, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprogress\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlog_suffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m _format == \u001b[33m\"\u001b[39m\u001b[33mtensorboard\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m467\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorBoardOutputFormat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    469\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown format specified: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Noah_tmp/thesis/Minigrid2Storm/.venv/lib/python3.12/site-packages/stable_baselines3/common/logger.py:399\u001b[39m, in \u001b[36mTensorBoardOutputFormat.__init__\u001b[39m\u001b[34m(self, folder)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, folder: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m SummaryWriter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mtensorboard is not installed, you can use `pip install tensorboard` to do so\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    400\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = SummaryWriter(log_dir=folder)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28mself\u001b[39m._is_closed = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: tensorboard is not installed, you can use `pip install tensorboard` to do so"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=MinigridFeaturesExtractor,\n",
    "    features_extractor_kwargs=dict(features_dim=128),\n",
    ")\n",
    "\n",
    "#Logging for PPO\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "log_dir = \"./logs/ppo_minigrid/\"\n",
    "PPO_logger = configure(log_dir, [\"stdout\", \"csv\"])\n",
    "\n",
    "\n",
    "model = PPO(\"CnnPolicy\", env, policy_kwargs=policy_kwargs, verbose=1,)\n",
    "model.set_logger(PPO_logger)\n",
    "model.learn(total_timesteps=1e5,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f4d203",
   "metadata": {},
   "source": [
    "Note that in case the policy is not performing well yet (cf. episode reward mean in the output of the previous cell), you could opt to just do it again. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01411527",
   "metadata": {},
   "source": [
    "Finally, let's save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"policies/PPO_{env_name}-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acbe778",
   "metadata": {},
   "source": [
    "### **Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0518d06",
   "metadata": {},
   "source": [
    "Note that you could load the model again with ``model = PPO.load(\"filename\")``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6faa991",
   "metadata": {},
   "source": [
    "For evaluation we use the evaluate_policy method from sb3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e24646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "\n",
    "evaluate_policy(model, env, n_eval_episodes=1000, render=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minigrid2storm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
